# Pinecone Configuration
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=your_pinecone_environment_here
PINECONE_INDEX_NAME=jarvis-assistant

# LLM Configuration
# For Ollama (local LLaMA), make sure Ollama is installed and running
OLLAMA_MODEL=llama2
# Alternative: Use OpenAI (if you prefer cloud-based LLM)
# OPENAI_API_KEY=your_openai_api_key_here
